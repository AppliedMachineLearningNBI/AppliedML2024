{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIV-Inhibiting Molecule Classification using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "\n",
    "1. Introduce the problem and the dataset\n",
    "2. Import libraries\n",
    "3. Load the data\n",
    "4. Visualize the data\n",
    "5. Visualize the metrics that need to be achieved\n",
    "6. Try logistic regression\n",
    "7. Try a simple neural network\n",
    "8. Try a simple GCN\n",
    "9. Try a simple GAT\n",
    "10. Try playing with convolution and aggregation styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (1.26.4)\n",
      "Requirement already satisfied: scipy==1.13.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (1.13.0)\n",
      "Requirement already satisfied: matplotlib==3.8.4 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (3.8.4)\n",
      "Collecting pandas==1.4.1 (from -r requirements.txt (line 21))\n",
      "  Using cached pandas-1.4.1-cp312-cp312-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: h5py==3.10.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (3.10.0)\n",
      "Requirement already satisfied: scikit-learn==1.4.2 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (1.4.2)\n",
      "Requirement already satisfied: xgboost==1.5.2 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (1.5.2)\n",
      "Requirement already satisfied: lightgbm==4.3.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (4.3.0)\n",
      "Requirement already satisfied: seaborn==0.13.2 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (0.13.2)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (0.17.2)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (2.2.2)\n",
      "Requirement already satisfied: torch-geometric in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (2.5.3)\n",
      "Collecting lightning (from -r requirements.txt (line 31))\n",
      "  Downloading lightning-2.2.4-py3-none-any.whl.metadata (53 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m982.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorboard in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (2.16.2)\n",
      "Collecting ogb (from -r requirements.txt (line 33))\n",
      "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib==3.8.4->-r requirements.txt (line 20)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib==3.8.4->-r requirements.txt (line 20)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib==3.8.4->-r requirements.txt (line 20)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib==3.8.4->-r requirements.txt (line 20)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib==3.8.4->-r requirements.txt (line 20)) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib==3.8.4->-r requirements.txt (line 20)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib==3.8.4->-r requirements.txt (line 20)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib==3.8.4->-r requirements.txt (line 20)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from pandas==1.4.1->-r requirements.txt (line 21)) (2023.3.post1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from scikit-learn==1.4.2->-r requirements.txt (line 23)) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from scikit-learn==1.4.2->-r requirements.txt (line 23)) (3.4.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->-r requirements.txt (line 27)) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->-r requirements.txt (line 27)) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->-r requirements.txt (line 27)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->-r requirements.txt (line 27)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->-r requirements.txt (line 27)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->-r requirements.txt (line 27)) (2023.10.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from torch-geometric->-r requirements.txt (line 30)) (4.66.2)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from torch-geometric->-r requirements.txt (line 30)) (3.9.5)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from torch-geometric->-r requirements.txt (line 30)) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from torch-geometric->-r requirements.txt (line 30)) (5.9.8)\n",
      "Collecting PyYAML<8.0,>=5.4 (from lightning->-r requirements.txt (line 31))\n",
      "  Downloading PyYAML-6.0.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning->-r requirements.txt (line 31))\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting torchmetrics<3.0,>=0.7.0 (from lightning->-r requirements.txt (line 31))\n",
      "  Downloading torchmetrics-1.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pytorch-lightning (from lightning->-r requirements.txt (line 31))\n",
      "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from tensorboard->-r requirements.txt (line 32)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from tensorboard->-r requirements.txt (line 32)) (1.62.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from tensorboard->-r requirements.txt (line 32)) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from tensorboard->-r requirements.txt (line 32)) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from tensorboard->-r requirements.txt (line 32)) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from tensorboard->-r requirements.txt (line 32)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from tensorboard->-r requirements.txt (line 32)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from tensorboard->-r requirements.txt (line 32)) (3.0.2)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from ogb->-r requirements.txt (line 33)) (2.2.1)\n",
      "Collecting outdated>=0.2.0 (from ogb->-r requirements.txt (line 33))\n",
      "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from aiohttp->torch-geometric->-r requirements.txt (line 30)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from aiohttp->torch-geometric->-r requirements.txt (line 30)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from aiohttp->torch-geometric->-r requirements.txt (line 30)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from aiohttp->torch-geometric->-r requirements.txt (line 30)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from aiohttp->torch-geometric->-r requirements.txt (line 30)) (1.9.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting littleutils (from outdated>=0.2.0->ogb->-r requirements.txt (line 33))\n",
      "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 32)) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->torch-geometric->-r requirements.txt (line 30)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->torch-geometric->-r requirements.txt (line 30)) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->torch-geometric->-r requirements.txt (line 30)) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/envs/py312/lib/python3.12/site-packages (from sympy->torch->-r requirements.txt (line 27)) (1.3.0)\n",
      "Downloading lightning-2.2.4-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Downloading PyYAML-6.0.1-cp312-cp312-macosx_10_9_x86_64.whl (178 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: littleutils\n",
      "  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7028 sha256=4211ce399747980ecdcbc40703f81551944924ec63f00d435e53e7d535a49c85\n",
      "  Stored in directory: /Users/petersen/Library/Caches/pip/wheels/20/bc/bd/732b4dc8cb7b7e1f9f21833e69a931bdcb11e1c21951fc4ff1\n",
      "Successfully built littleutils\n",
      "Installing collected packages: littleutils, PyYAML, lightning-utilities, pandas, outdated, torchmetrics, ogb, pytorch-lightning, lightning\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastparquet 0.0.0 requires pandas>=1.5.0, but you have pandas 1.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.1 lightning-2.2.4 lightning-utilities-0.11.2 littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2 pandas-1.4.1 pytorch-lightning-2.2.4 torchmetrics-1.3.2\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
      "Collecting torch_scatter\n",
      "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: torch_scatter\n",
      "  Building wheel for torch_scatter (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[406 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-312\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/placeholder.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_csr.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_coo.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/utils.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/scatter.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/testing.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/std.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/logsumexp.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/softmax.py -> build/lib.macosx-10.9-x86_64-cpython-312/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_scatter.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_scatter.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_scatter.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torch_scatter._scatter_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-x86_64-cpython-312\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-x86_64-cpython-312/csrc\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-x86_64-cpython-312/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m clang -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/anaconda3/envs/py312/include -fPIC -O2 -isystem /opt/anaconda3/envs/py312/include -DWITH_PYTHON -Icsrc -I/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include -I/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/TH -I/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/THC -I/opt/anaconda3/envs/py312/include/python3.12 -c csrc/cpu/scatter_cpu.cpp -o build/temp.macosx-10.9-x86_64-cpython-312/csrc/cpu/scatter_cpu.o -O3 -Wno-sign-compare -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -DTORCH_EXTENSION_NAME=_scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:28:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/c10/util/OptionalArrayRef.h:159:34: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m     return wrapped_opt_array_ref.value();\n",
      "  \u001b[31m   \u001b[0m                                  ^\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/c10/util/OptionalArrayRef.h:222:13: note: in instantiation of member function 'c10::OptionalArrayRef<long long>::value' requested here\n",
      "  \u001b[31m   \u001b[0m   return a1.value() == other;\n",
      "  \u001b[31m   \u001b[0m             ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:943:33: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type const& value() const&\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:31:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/CheckMemoryFormat.h:11:35: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m       options.requires_grad_opt().value() == false,\n",
      "  \u001b[31m   \u001b[0m                                   ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:961:28: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type&& value() &&\n",
      "  \u001b[31m   \u001b[0m                            ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:33:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/DeprecatedTypeProperties.h:110:34: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m       Device device = device_opt.value();\n",
      "  \u001b[31m   \u001b[0m                                  ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:952:27: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type& value() &\n",
      "  \u001b[31m   \u001b[0m                           ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:442:26: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m       TORCH_CHECK(inputs.value().size() > 0, \"'inputs' argument to backward cannot be empty\")\n",
      "  \u001b[31m   \u001b[0m                          ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:952:27: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type& value() &\n",
      "  \u001b[31m   \u001b[0m                           ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:443:30: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m       this->_backward(inputs.value(), gradient, retain_graph, create_graph);\n",
      "  \u001b[31m   \u001b[0m                              ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:952:27: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type& value() &\n",
      "  \u001b[31m   \u001b[0m                           ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:28:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/c10/util/OptionalArrayRef.h:131:34: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m     return wrapped_opt_array_ref.value();\n",
      "  \u001b[31m   \u001b[0m                                  ^\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:5606:152: note: in instantiation of member function 'c10::OptionalArrayRef<long long>::operator*' requested here\n",
      "  \u001b[31m   \u001b[0m     return at::_ops::to_padded_tensor::call(const_cast<Tensor&>(*this), padding, output_size.has_value() ? c10::make_optional(c10::fromIntArrayRefSlow(*output_size)) : c10::nullopt);\n",
      "  \u001b[31m   \u001b[0m                                                                                                                                                        ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:952:27: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type& value() &\n",
      "  \u001b[31m   \u001b[0m                           ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:11:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/NamedTensorUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/TensorNames.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/WrapDimUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef.h:631:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List.h:490:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:4:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1551:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:12:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:662:24: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m       prod *= shape[i].value();\n",
      "  \u001b[31m   \u001b[0m                        ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:943:33: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type const& value() const&\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:11:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/NamedTensorUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/TensorNames.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/WrapDimUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef.h:631:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List.h:490:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:4:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1551:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:12:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:1512:28: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m     const auto& n = name().value();\n",
      "  \u001b[31m   \u001b[0m                            ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:943:33: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type const& value() const&\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:11:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/NamedTensorUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/TensorNames.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/WrapDimUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef.h:631:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List.h:490:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:4:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1551:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:12:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:2129:20: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m     return reason_.value();\n",
      "  \u001b[31m   \u001b[0m                    ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:943:33: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type const& value() const&\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:11:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/NamedTensorUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/TensorNames.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/WrapDimUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef.h:631:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List.h:490:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:4:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1551:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:16:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/c10/core/DeviceGuard.h:3:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineDeviceGuard.h:230:33: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m       guard_.emplace(device_opt.value());\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:952:27: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type& value() &\n",
      "  \u001b[31m   \u001b[0m                           ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:11:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/NamedTensorUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/TensorNames.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/WrapDimUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef.h:631:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List.h:490:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:4:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1551:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:16:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/c10/core/DeviceGuard.h:3:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineDeviceGuard.h:242:39: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m       guard_.emplace(device_index_opt.value());\n",
      "  \u001b[31m   \u001b[0m                                       ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:952:27: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type& value() &\n",
      "  \u001b[31m   \u001b[0m                           ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:11:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/NamedTensorUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/TensorNames.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/WrapDimUtils.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef.h:631:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List.h:490:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:4:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1551:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:20:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/c10/core/StreamGuard.h:3:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineStreamGuard.h:146:33: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m       guard_.emplace(stream_opt.value());\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:952:27: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type& value() &\n",
      "  \u001b[31m   \u001b[0m                           ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:28:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/c10/util/OptionalArrayRef.h:155:34: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m     return wrapped_opt_array_ref.value();\n",
      "  \u001b[31m   \u001b[0m                                  ^\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/WrapDimUtilsMulti.h:26:26: note: in instantiation of member function 'c10::OptionalArrayRef<long long>::value' requested here\n",
      "  \u001b[31m   \u001b[0m     auto dims = opt_dims.value();\n",
      "  \u001b[31m   \u001b[0m                          ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:952:27: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type& value() &\n",
      "  \u001b[31m   \u001b[0m                           ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:628:27: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m     return backward_info_.value();\n",
      "  \u001b[31m   \u001b[0m                           ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:943:33: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type const& value() const&\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:665:47: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m     return shared_view_info_ ? backward_info_.value() : forward_info_.value();\n",
      "  \u001b[31m   \u001b[0m                                               ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:943:33: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type const& value() const&\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:665:71: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m     return shared_view_info_ ? backward_info_.value() : forward_info_.value();\n",
      "  \u001b[31m   \u001b[0m                                                                       ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:943:33: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type const& value() const&\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:4:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd_not_implemented_fallback.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/library.h:61:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/function_schema.h:595:29: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m         arg.default_value().value().isString()) {\n",
      "  \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:943:33: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type const& value() const&\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:4:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd_not_implemented_fallback.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/library.h:61:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/function_schema.h:596:50: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m       printQuotedString(out, arg.default_value().value().toStringRef());\n",
      "  \u001b[31m   \u001b[0m                                                  ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:943:33: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type const& value() const&\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:4:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd_not_implemented_fallback.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/torch/library.h:61:\n",
      "  \u001b[31m   \u001b[0m In file included from /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8:\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/include/ATen/core/function_schema.h:603:46: error: 'value' is unavailable: introduced in macOS 10.14\n",
      "  \u001b[31m   \u001b[0m       auto default_val = arg.default_value().value().toIntList();\n",
      "  \u001b[31m   \u001b[0m                                              ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/optional:943:33: note: 'value' has been explicitly marked unavailable here\n",
      "  \u001b[31m   \u001b[0m     constexpr value_type const& value() const&\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m fatal error: too many errors emitted, stopping now [-ferror-limit=]\n",
      "  \u001b[31m   \u001b[0m 20 errors generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch_scatter\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch_scatter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build torch_scatter\r\n",
      "\u001b[31mERROR: Could not build wheels for torch_scatter, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Assuming you have a conda env already set up\n",
    "!pip install -r requirements.txt\n",
    "# This next install depends on whether you have a cpu or gpu. If you have a gpu, you can install the gpu version of torch_geometric\n",
    "# If you have a cpu, you can install the cpu version of torch_geometric\n",
    "# If you have a gpu, run the following command\n",
    "!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
    "# If you have a cpu, run the following command\n",
    "#!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.3.0+cpu.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nodes in the graph have features given by `graph.x`:\n",
    "- atomic_num: the atomic number of the atom\n",
    "- chirality: the chirality of the atom\n",
    "- degree: the degree of the atom\n",
    "- formal_charge: the formal charge of the atom\n",
    "- num_h: the number of hydrogens of the atom\n",
    "- num_rad_e: the number of radical electrons of the atom\n",
    "- hybridization: the hybridization of the atom\n",
    "- is_aromatic: whether the atom is aromatic\n",
    "- is_in_ring: whether the atom is in a ring\n",
    "\n",
    "The edges in the graph have features given by `graph.edge_attr`: \n",
    "- bond_type: the type of the bond\n",
    "- bond_stereo: the stereo of the bond\n",
    "- is_conjugated: whether the bond is conjugated\n",
    "\n",
    "The graph has just one \"feature\", which is a binary label indicating whether the molecule is an HIV-inhibitor or not:\n",
    "- `graph.y`: whether the molecule is an HIV-inhibitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ogb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-32c46e675bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mogb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphproppred\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPygGraphPropPredDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPygGraphPropPredDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ogbg-molhiv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ogb'"
     ]
    }
   ],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = PygGraphPropPredDataset(name = \"ogbg-molhiv\") \n",
    "\n",
    "split_idx = dataset.get_idx_split() \n",
    "train_pyg_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True)\n",
    "valid_pyg_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False)\n",
    "test_pyg_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_graph = valid_pyg_loader.dataset[0]\n",
    "print(example_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Function to visualize graph based on target value\n",
    "def visualize_graph_with_target(loader, target_value):\n",
    "    for graph in loader.dataset:\n",
    "        if graph.y.item() == target_value:\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            atomic_number = graph.x[:, 0].numpy()\n",
    "            graph_networkx = to_networkx(graph.clone())\n",
    "            pos = nx.spring_layout(graph_networkx)\n",
    "            nx.draw_networkx(graph_networkx, pos, labels=dict(zip(range(len(atomic_number)), atomic_number)), node_size=300, node_color=atomic_number, cmap=\"tab20\")\n",
    "            plt.title(f\"Graph with target {graph.y.item()}\")\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "# Visualize graph with target 0\n",
    "visualize_graph_with_target(valid_pyg_loader, 0)\n",
    "\n",
    "# Visualize graph with target 1\n",
    "visualize_graph_with_target(valid_pyg_loader, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of graph sizes for true and false graphs\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_histograms_of_graph_sizes(loader):\n",
    "    true_sizes = []\n",
    "    false_sizes = []\n",
    "    for graph in loader.dataset:\n",
    "        if graph.y.item() == 1:\n",
    "            true_sizes.append(graph.num_nodes)\n",
    "        else:\n",
    "            false_sizes.append(graph.num_nodes)\n",
    "    \n",
    "    # Create a DataFrame to facilitate plotting with seaborn\n",
    "    data_true = pd.DataFrame({'Size': true_sizes, 'Target': 'True'})\n",
    "    data_false = pd.DataFrame({'Size': false_sizes, 'Target': 'False'})\n",
    "    data = pd.concat([data_true, data_false])\n",
    "    \n",
    "    # Plotting the histograms\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data, x='Size', hue='Target', element='step', kde=True, palette=['green', 'red'])\n",
    "    plt.title('Histogram of Graph Sizes for True and False Targets')\n",
    "    plt.xlabel('Graph Size')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "plot_histograms_of_graph_sizes(valid_pyg_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data is VERY imbalanced - most molecules are not useful for fighting HIV (as you might expect!). So we will need to be careful about how we evaluate our models. We can't simply use accuracy, as a model that always predicts \"not an HIV-inhibitor\" would be right 99% of the time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also histogram each of the node features, so we know what scales they are:\n",
    "def plot_histograms_of_node_features(loader):\n",
    "    feature_names = ['atomic_num', 'chirality', 'degree', 'formal_charge', 'num_h', 'num_rad_e', 'hybridization', 'is_aromatic', 'is_in_ring']\n",
    "    num_features = len(feature_names)\n",
    "    \n",
    "    # Create a 3x3 subplot grid\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes to 1D for easier iteration\n",
    "    \n",
    "    for i in range(num_features):\n",
    "        all_features = []\n",
    "        for graph in loader.dataset:\n",
    "            all_features.extend(graph.x[:, i].numpy())\n",
    "        \n",
    "        # Plot on the ith subplot\n",
    "        sns.histplot(all_features, element='step', ax=axes[i])\n",
    "        axes[i].set_title(f'Histogram of {feature_names[i]}')\n",
    "        axes[i].set_xlabel(f'{feature_names[i]} Value')\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].set_yscale('log')  # Set y-axis scale to logarithmic\n",
    "    \n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_histograms_of_node_features(valid_pyg_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the data is all of a similar scale, so we don't need to be too worried about normalizing. Maybe we could take the log of the atomic number, and add that as a feature. But that's about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the absolute most naive thing: Logistic regression. This will give us a baseline to compare against.\n",
    "The first question is what is the input to our logistic regression. It's non-obvious, since we have two problems:\n",
    "1. The input features are nodes in no obvious or particular order\n",
    "2. The list of nodes is different from one graph to the next\n",
    "\n",
    "So to make our first naive benchmark as simple as possible, let's take some simplifications to the dataset:\n",
    "1. Let's sort the nodes from largest to smallest atomic number\n",
    "2. Let's take the first 10 sorted nodes in each graph, and pad with zeros if there are fewer than 20 nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the nodes by atomic number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Function to preprocess and flatten graph data\n",
    "def preprocess_data(loader):\n",
    "    X, y = [], []\n",
    "    for data in loader.dataset:\n",
    "        # Sort nodes by atomic number in descending order\n",
    "        node_features = data.x\n",
    "        sorted_nodes = node_features[node_features[:, 0].argsort(descending=True)]\n",
    "        \n",
    "        # Add log of the first feature (atomic number) as a new feature\n",
    "        log_feature = np.log(sorted_nodes[:, 0] + 1).reshape(-1, 1)  # Adding 1 to avoid log(0)\n",
    "        sorted_nodes = np.hstack([sorted_nodes, log_feature])\n",
    "        \n",
    "        # Select the first N nodes\n",
    "        num_nodes = 20\n",
    "\n",
    "        # Select the first 20 nodes, pad if necessary\n",
    "        if len(sorted_nodes) < num_nodes:\n",
    "            padding = np.zeros((num_nodes - len(sorted_nodes), sorted_nodes.shape[1]))\n",
    "            sorted_nodes = np.vstack([sorted_nodes, padding])\n",
    "        elif len(sorted_nodes) > num_nodes:\n",
    "            sorted_nodes = sorted_nodes[:num_nodes]\n",
    "        \n",
    "        # Flatten the node features to create a single feature vector\n",
    "        flat_features = sorted_nodes.flatten()\n",
    "        X.append(flat_features)\n",
    "        y.append(data.y.item())\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Function to preprocess and flatten graph data\n",
    "def preprocess_data(loader):\n",
    "    X, y = [], []\n",
    "    # Initialize OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    \n",
    "    # Fit encoder on all possible atomic numbers (assuming atomic numbers range from 1 to 118)\n",
    "    encoder.fit(np.arange(1, 119).reshape(-1, 1))\n",
    "    \n",
    "    for data in loader.dataset:\n",
    "        # Sort nodes by atomic number in descending order\n",
    "        node_features = data.x\n",
    "        sorted_nodes = node_features[node_features[:, 0].argsort(descending=True)]\n",
    "        \n",
    "        # One-hot encode the atomic number\n",
    "        atomic_numbers = sorted_nodes[:, 0].reshape(-1, 1)\n",
    "        one_hot_atomic_numbers = encoder.transform(atomic_numbers)\n",
    "        \n",
    "        # Replace atomic number with its one-hot encoded version\n",
    "        sorted_nodes = np.hstack([one_hot_atomic_numbers, sorted_nodes[:, 1:]])\n",
    "        \n",
    "        # Add log of the first feature (atomic number) as a new feature\n",
    "        log_feature = np.log(sorted_nodes[:, 0] + 1).reshape(-1, 1)  # Adding 1 to avoid log(0)\n",
    "        sorted_nodes = np.hstack([sorted_nodes, log_feature])\n",
    "        \n",
    "        # Select the first N nodes\n",
    "        num_nodes = 20\n",
    "\n",
    "        # Select the first 20 nodes, pad if necessary\n",
    "        if len(sorted_nodes) < num_nodes:\n",
    "            padding = np.zeros((num_nodes - len(sorted_nodes), sorted_nodes.shape[1]))\n",
    "            sorted_nodes = np.vstack([sorted_nodes, padding])\n",
    "        elif len(sorted_nodes) > num_nodes:\n",
    "            sorted_nodes = sorted_nodes[:num_nodes]\n",
    "        \n",
    "        # Flatten the node features to create a single feature vector\n",
    "        flat_features = sorted_nodes.flatten()\n",
    "        X.append(flat_features)\n",
    "        y.append(data.y.item())\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X_train, y_train = preprocess_data(train_pyg_loader)\n",
    "X_valid, y_valid = preprocess_data(valid_pyg_loader)\n",
    "X_test, y_test = preprocess_data(test_pyg_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_valid = model.predict(X_valid)\n",
    "y_pred_test = model.predict(X_test)\n",
    "valid_accuracy = accuracy_score(y_valid, y_pred_valid)\n",
    "valid_auc = roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1])\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "test_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Validation Accuracy: {valid_accuracy}\")\n",
    "print(f\"Validation AUC: {valid_auc}\")\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test AUC: {test_auc}\")\n",
    "\n",
    "# Also get the ROC AUC for a random classifier\n",
    "random_preds = np.random.rand(len(y_test))\n",
    "random_auc = roc_auc_score(y_test, random_preds)\n",
    "\n",
    "fpr_valid, tpr_valid, _ = roc_curve(y_valid, model.predict_proba(X_valid)[:, 1])\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_valid, tpr_valid, label='Validation')\n",
    "plt.plot(fpr_test, tpr_test, label='Test')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='black')\n",
    "plt.text(0.7, 0.3, f'Valid AUC: {valid_auc:.2f}', fontsize=12)\n",
    "plt.text(0.7, 0.2, f'Test AUC: {test_auc:.2f}', fontsize=12)\n",
    "plt.text(0.7, 0.1, f'Random AUC: {random_auc:.2f}', fontsize=12)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Logistic Regression')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we're better than a coin flip. Not bad for 3 seconds of work. But we have a long way to go if we want to get onto the OGB Leaderboard for this benchmark:\n",
    "![OGB Leaderboard](img/mol_hiv_leaderboard.png)\n",
    "\n",
    "So let's try something more sophisticated...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "bdt_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "bdt_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using AUC\n",
    "y_prob_valid_bdt = bdt_model.predict_proba(X_valid)[:, 1]  # Get probabilities for the positive class\n",
    "y_prob_test_bdt = bdt_model.predict_proba(X_test)[:, 1]    # Get probabilities for the positive class\n",
    "\n",
    "valid_auc_bdt = roc_auc_score(y_valid, y_prob_valid_bdt)\n",
    "test_auc_bdt = roc_auc_score(y_test, y_prob_test_bdt)\n",
    "\n",
    "print(f\"Validation AUC (BDT): {valid_auc_bdt}\")\n",
    "print(f\"Test AUC (BDT): {test_auc_bdt}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_valid_bdt, tpr_valid_bdt, _ = roc_curve(y_valid, y_prob_valid_bdt)\n",
    "fpr_test_bdt, tpr_test_bdt, _ = roc_curve(y_test, y_prob_test_bdt)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_valid_bdt, tpr_valid_bdt, label='Validation (BDT)')\n",
    "plt.plot(fpr_test_bdt, tpr_test_bdt, label='Test (BDT)')\n",
    "plt.plot(fpr_valid, tpr_valid, label='Validation (LR)')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='black')\n",
    "plt.text(0.7, 0.3, f'Validation AUC (BDT): {valid_auc_bdt:.2f}', fontsize=12)\n",
    "plt.text(0.7, 0.2, f'Test AUC (BDT): {test_auc_bdt:.2f}', fontsize=12)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creeping up... but still a long way to go to an AUC of 0.84. Let's try a simple neural network next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this simple neural network, let's switch back to pytorch. In particular, let's use pytorch lightning to avoid boilerplate code. (If you haven't used pytorch or pytorch lightning before, you can think of pytorch = tensorboard, and pytorch lightning = keras). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as lit\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from lightning.pytorch import Trainer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from lightning.pytorch.loggers import CSVLogger  # Import CSVLogger\n",
    "import numpy as np\n",
    "\n",
    "def prepare_data_loaders(X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size=32):\n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "    valid_dataset = TensorDataset(torch.FloatTensor(X_valid), torch.FloatTensor(y_valid))\n",
    "    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "def make_mlp(\n",
    "    input_size,\n",
    "    sizes,\n",
    "    hidden_activation=\"ReLU\",\n",
    "    output_activation=None,\n",
    "    layer_norm=False,\n",
    "):\n",
    "    \"\"\"Construct an MLP with specified fully-connected layers.\"\"\"\n",
    "    hidden_activation = getattr(nn, hidden_activation)()\n",
    "    output_activation = getattr(nn, output_activation)() if output_activation else None\n",
    "    layers = []\n",
    "    sizes = [input_size] + sizes\n",
    "\n",
    "    # Add hidden layers\n",
    "    for i in range(len(sizes) - 2):  # Change the range to stop before the last hidden layer\n",
    "        layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "        if layer_norm:\n",
    "            layers.append(nn.LayerNorm(sizes[i + 1], elementwise_affine=False))\n",
    "        layers.append(hidden_activation)\n",
    "\n",
    "    # Add final layer\n",
    "    layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
    "    if output_activation:\n",
    "        layers.append(output_activation)\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class BaseLitModel(lit.LightningModule):\n",
    "    def __init__(self, lr=1e-3, weight_decay=0, lr_decay=0.95):\n",
    "        super().__init__()\n",
    "\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.val_preds = []\n",
    "        self.val_targets = []\n",
    "        self.test_preds = []\n",
    "        self.test_targets = []\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.lr_decay = lr_decay\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y_hat, y = self.apply_model(batch)\n",
    "        # Check if y needs to be unsqueezed\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.unsqueeze(1)\n",
    "        loss = self.criterion(y_hat, y.float())\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)  # Log on progress bar\n",
    "        self.log('learning_rate', self.trainer.optimizers[0].param_groups[0]['lr'], on_step=False, on_epoch=True, prog_bar=True)  # Log current learning rate\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_hat, y = self.apply_model(batch)\n",
    "        # Check if y needs to be unsqueezed\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.unsqueeze(1)\n",
    "        loss = self.criterion(y_hat, y.float())\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)  # Log on progress bar\n",
    "        self.val_preds.extend(y_hat.view(-1).detach().cpu().numpy())\n",
    "        self.val_targets.extend(y.view(-1).detach().cpu().numpy())\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        y_hat, y = self.apply_model(batch)\n",
    "        # Check if y needs to be unsqueezed\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.unsqueeze(1)\n",
    "        loss = self.criterion(y_hat, y.float())\n",
    "        self.log('test_loss', loss, on_epoch=True, prog_bar=True)  # Log on progress bar\n",
    "        self.test_preds.extend(y_hat.view(-1).detach().cpu().numpy())\n",
    "        self.test_targets.extend(y.view(-1).detach().cpu().numpy())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        lr_scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: self.lr_decay ** epoch),\n",
    "            'name': 'lambda_decay'\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "class AUCCallback(Callback):\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        val_auc = roc_auc_score(pl_module.val_targets, pl_module.val_preds)\n",
    "        pl_module.log(\"val_auc\", val_auc, prog_bar=True)  # Log on progress bar\n",
    "        pl_module.val_preds = []\n",
    "        pl_module.val_targets = []\n",
    "\n",
    "    def on_test_epoch_end(self, trainer, pl_module):\n",
    "        test_auc = roc_auc_score(pl_module.test_targets, pl_module.test_preds)\n",
    "        pl_module.log(\"test_auc\", test_auc, prog_bar=True)  # Log on progress bar\n",
    "        pl_module.test_preds = []\n",
    "        pl_module.test_targets = []\n",
    "\n",
    "# Prepare data loaders\n",
    "def prepare_data_loaders(X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size=32):\n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "    valid_dataset = TensorDataset(torch.FloatTensor(X_valid), torch.FloatTensor(y_valid))\n",
    "    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(BaseLitModel):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleMLP, self).__init__(lr=1e-3, weight_decay=0, lr_decay=0.90)\n",
    "        self.model = make_mlp(input_size, \n",
    "                              [hidden_size]*3 + [output_size],\n",
    "                              hidden_activation=\"ReLU\", \n",
    "                              layer_norm=True,\n",
    "                              output_activation=\"Sigmoid\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def apply_model(self, batch):\n",
    "        x, y = batch\n",
    "        return self(x), y\n",
    "        \n",
    "# Data loaders\n",
    "train_loader, valid_loader, test_loader = prepare_data_loaders(X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "\n",
    "# Initialize the model\n",
    "input_size = train_loader.dataset[0][0].shape[0]  # Adjust input size for the new feature\n",
    "hidden_size = 64  # You can tune this parameter\n",
    "output_size = 1\n",
    "model = SimpleMLP(input_size, hidden_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "auc_callback = AUCCallback()\n",
    "csv_logger = CSVLogger('lightning_logs', name='mlp_model')  # Initialize CSVLogger\n",
    "trainer = Trainer(max_epochs=10, accelerator=\"gpu\", callbacks=[auc_callback], logger=csv_logger)  # Add logger to Trainer\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_latest_directory(base_path):\n",
    "    list_of_files = glob.glob(f'{base_path}/version_*')\n",
    "    latest_dir = max(list_of_files, key=os.path.getmtime)\n",
    "    return latest_dir\n",
    "\n",
    "def plot_metrics(directory, model_name):\n",
    "    metrics_file = os.path.join(directory, 'metrics.csv')\n",
    "    metrics_df = pd.read_csv(metrics_file)\n",
    "    train_loss_df = metrics_df[metrics_df['train_loss'].notna()]\n",
    "    val_loss_df = metrics_df[metrics_df['val_loss'].notna()]\n",
    "    val_auc_df = metrics_df[metrics_df['val_auc'].notna()]\n",
    "    learning_rate_df = metrics_df[metrics_df['learning_rate'].notna()]  # Extract learning rate data\n",
    "\n",
    "    plt.figure(figsize=(16, 4))  # Adjusted figure size to accommodate new subplot\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.plot(train_loss_df['step'], train_loss_df['train_loss'], label='Training Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xscale('log')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.plot(val_loss_df['epoch'], val_loss_df['val_loss'], label='Validation Loss')\n",
    "    plt.title('Validation Loss Over Epochs')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xscale('log')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.plot(val_auc_df['epoch'], val_auc_df['val_auc'], label='Validation AUC')\n",
    "    plt.title('Validation AUC Over Epochs')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.xscale('log')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.plot(learning_rate_df['epoch'], learning_rate_df['learning_rate'], label='Learning Rate')\n",
    "    plt.title('Learning Rate Over Epochs')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.xscale('log')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'lightning_logs/mlp_model'\n",
    "latest_dir = find_latest_directory(base_path)\n",
    "plot_metrics(latest_dir, 'MLP Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a simple graph convolution network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're struggling to beat the BDT - it's just too good at consuming tabular data. But we have a secret weapon: the graph structure! Let's try a simple graph convolution network. We will use the industry-standard PyG (\"Pytorch Geometric\") library for this, with its built-in GCN implementation. But first, let's try to code up a GCN from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as lit\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from lightning.pytorch import Trainer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv, aggr\n",
    "from lightning.pytorch.loggers import CSVLogger  # Import CSVLogger\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "class GCN(BaseLitModel):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GCN, self).__init__(lr=1e-3, weight_decay=0, lr_decay=0.90)\n",
    "        self.node_network_1 = make_mlp(input_size, [hidden_size]*2, layer_norm=True, hidden_activation=\"ReLU\")\n",
    "        self.conv = GCNConv(hidden_size, hidden_size)\n",
    "        self.node_network_2 = make_mlp(hidden_size, [hidden_size]*2, layer_norm=True, hidden_activation=\"ReLU\")\n",
    "        self.output_network = make_mlp(hidden_size, [output_size], layer_norm=True, hidden_activation=\"ReLU\", output_activation=\"Sigmoid\")\n",
    "        self.aggregation = aggr.MeanAggregation()\n",
    "\n",
    "    def forward(self, graph):\n",
    "        x = self.node_network_1(graph.x.float())\n",
    "        x = self.conv(x, graph.edge_index)\n",
    "        x = self.node_network_2(x)\n",
    "        x = self.aggregation(x, graph.batch)\n",
    "        return self.output_network(x)\n",
    "\n",
    "    def apply_model(self, batch):\n",
    "        return self(batch), batch.y\n",
    "\n",
    "# Initialize the model\n",
    "input_size = train_pyg_loader.dataset[0].x.shape[1]\n",
    "hidden_size = 64  # You can tune this parameter\n",
    "output_size = 1\n",
    "model = GCN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "auc_callback = AUCCallback()\n",
    "csv_logger = CSVLogger('lightning_logs', name='gcn_model')  # Initialize CSVLogger\n",
    "trainer = Trainer(max_epochs=10, accelerator=\"gpu\", callbacks=[auc_callback], logger=csv_logger)  # Add logger to Trainer\n",
    "trainer.fit(model, train_pyg_loader, valid_pyg_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'lightning_logs/gcn_model'\n",
    "latest_dir = find_latest_directory(base_path)\n",
    "plot_metrics(latest_dir, 'GCN Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test graph attention network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "class GAT(BaseLitModel):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GAT, self).__init__(lr=1e-3, weight_decay=0, lr_decay=0.90)\n",
    "        self.node_network_1 = make_mlp(input_size, [hidden_size]*2, layer_norm=True, hidden_activation=\"ReLU\")\n",
    "        self.conv = GATv2Conv(hidden_size, hidden_size, heads=1)\n",
    "        self.node_network_2 = make_mlp(hidden_size, [hidden_size]*2, layer_norm=True, hidden_activation=\"ReLU\")\n",
    "        self.output_network = make_mlp(hidden_size, [output_size], layer_norm=True, hidden_activation=\"ReLU\", output_activation=\"Sigmoid\")\n",
    "        self.aggregation = aggr.MeanAggregation()\n",
    "\n",
    "    def forward(self, graph):\n",
    "        x = self.node_network_1(graph.x.float())\n",
    "        x = self.conv(x, graph.edge_index)\n",
    "        x = self.node_network_2(x)\n",
    "        x = self.aggregation(x, graph.batch)\n",
    "        return self.output_network(x)\n",
    "\n",
    "    def apply_model(self, batch):\n",
    "        return self(batch), batch.y\n",
    "\n",
    "# Initialize the model\n",
    "input_size = train_pyg_loader.dataset[0].x.shape[1]\n",
    "hidden_size = 64  # You can tune this parameter\n",
    "output_size = 1\n",
    "model = GAT(input_size, hidden_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "auc_callback = AUCCallback()\n",
    "csv_logger = CSVLogger('lightning_logs', name='gat_model')  # Initialize CSVLogger\n",
    "trainer = Trainer(max_epochs=10, accelerator=\"gpu\", callbacks=[auc_callback], logger=csv_logger)  # Add logger to Trainer\n",
    "trainer.fit(model, train_pyg_loader, valid_pyg_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'lightning_logs/gat_model'\n",
    "latest_dir = find_latest_directory(base_path)\n",
    "plot_metrics(latest_dir, 'GAT Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_scatter import scatter_mean, scatter_add\n",
    "from torch import nn\n",
    "\n",
    "class InteractionGNN(BaseLitModel):\n",
    "    def __init__(self, hparams):\n",
    "        super(InteractionGNN, self).__init__(lr=hparams['lr'], weight_decay=hparams['weight_decay'], lr_decay=hparams['lr_decay'])\n",
    "\n",
    "        # Node and Edge Networks\n",
    "        self.input_node_network = make_mlp(\n",
    "            input_size=hparams['input_size'],\n",
    "            sizes=[hparams['hidden_size']] * 2,\n",
    "            layer_norm=True,\n",
    "            hidden_activation=\"ReLU\"\n",
    "        )\n",
    "        self.node_network = make_mlp(\n",
    "            input_size=hparams['hidden_size'],\n",
    "            sizes=[hparams['hidden_size']] * 2,\n",
    "            layer_norm=True,\n",
    "            hidden_activation=\"ReLU\"\n",
    "        )\n",
    "        self.edge_network = make_mlp(\n",
    "            input_size=2 * hparams['hidden_size'],\n",
    "            sizes=[hparams['hidden_size']] * 2,\n",
    "            layer_norm=True,\n",
    "            hidden_activation=\"ReLU\"\n",
    "        )\n",
    "        self.output_network = make_mlp(\n",
    "            input_size=hparams['hidden_size'],\n",
    "            sizes=[hparams['output_size']],\n",
    "            layer_norm=True,\n",
    "            hidden_activation=\"ReLU\",\n",
    "            output_activation=\"Sigmoid\"\n",
    "        )\n",
    "        self.num_graph_iters = hparams['num_graph_iters']\n",
    "\n",
    "        self.aggregation = scatter_add\n",
    "\n",
    "    def forward(self, graph):\n",
    "        x, edge_index = graph.x.float(), graph.edge_index\n",
    "        x = self.input_node_network(x)\n",
    "\n",
    "        for _ in range(self.num_graph_iters):\n",
    "            # Save the input to the iteration for the skip connection\n",
    "            x_skip = x\n",
    "\n",
    "            # Edge features update\n",
    "            start, end = edge_index\n",
    "            edge_features = torch.cat([x[start], x[end]], dim=1)\n",
    "            e = self.edge_network(edge_features)\n",
    "\n",
    "            # Message passing\n",
    "            x = self.aggregation(e, end, dim=0, dim_size=x.size(0))  # Aggregating messages to target nodes\n",
    "\n",
    "            # Node features update\n",
    "            x = self.node_network(x)\n",
    "\n",
    "            # Adding skip connection\n",
    "            x = x + x_skip\n",
    "\n",
    "        # Aggregate to graph level\n",
    "        x = self.aggregation(x, graph.batch, dim=0)\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.output_network(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def apply_model(self, batch):\n",
    "        return self(batch), batch.y\n",
    "\n",
    "# Example usage\n",
    "hparams = {\n",
    "    'input_size': train_pyg_loader.dataset[0].x.shape[1],\n",
    "    'hidden_size': 64,\n",
    "    'output_size': 1,\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 1e-5,\n",
    "    'lr_decay': 0.97,\n",
    "    'num_graph_iters': 3  # Number of graph iterations\n",
    "}\n",
    "model = InteractionGNN(hparams)\n",
    "\n",
    "# Training setup remains the same\n",
    "auc_callback = AUCCallback()\n",
    "csv_logger = CSVLogger('lightning_logs', name='interaction_gnn_model')\n",
    "trainer = Trainer(max_epochs=50, accelerator=\"gpu\", callbacks=[auc_callback], logger=csv_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.tuner import Tuner\n",
    "# Create a Tuner\n",
    "tuner = Tuner(trainer)\n",
    "\n",
    "# finds learning rate automatically\n",
    "# sets hparams.lr or hparams.learning_rate to that learning rate\n",
    "tuner.lr_find(model, train_pyg_loader, valid_pyg_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_pyg_loader, valid_pyg_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'lightning_logs/interaction_gnn_model'\n",
    "latest_dir = find_latest_directory(base_path)\n",
    "plot_metrics(latest_dir, 'Interaction GNN Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "trainer.test(model, test_pyg_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import Evaluator\n",
    "\n",
    "evaluator = Evaluator(name = 'ogbg-molhiv')\n",
    "\n",
    "y_true = torch.cat([graph.y for graph in valid_pyg_loader]).numpy()\n",
    "with torch.no_grad():\n",
    "    y_pred = torch.cat([model(graph) for graph in valid_pyg_loader]).numpy()\n",
    "input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "result_dict = evaluator.eval(input_dict)\n",
    "print(\"VALIDATION RESULTS\", result_dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import Evaluator\n",
    "\n",
    "evaluator = Evaluator(name = 'ogbg-molhiv')\n",
    "\n",
    "y_true = torch.cat([graph.y for graph in test_pyg_loader]).numpy()\n",
    "with torch.no_grad():\n",
    "    y_pred = torch.cat([model(graph) for graph in test_pyg_loader]).numpy()\n",
    "input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "result_dict = evaluator.eval(input_dict)\n",
    "print(\"TEST RESULTS\", result_dict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with convolution and aggregation styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tweak the convolution and aggregation styles to see if we can improve the performance of our model. E.g. we can try scatter max, scatter std, combine scatter operations, or we can try the MANY different convolutions available in PyG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
