{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A larger example\n",
    "\n",
    "Here we will use a dataset on Italian wine. The dataset is taken from\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/\n",
    "\n",
    "The actual data is in the file wine.data, and a description of the data can be found in wine.names.\n",
    "\n",
    "If we look at the beginning of the data file we see:<br>\n",
    "`1,14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065\n",
    "1,13.2,1.78,2.14,11.2,100,2.65,2.76,.26,1.28,4.38,1.05,3.4,1050\n",
    "1,13.16,2.36,2.67,18.6,101,2.8,3.24,.3,2.81,5.68,1.03,3.17,1185\n",
    "1,14.37,1.95,2.5,16.8,113,3.85,3.49,.24,2.18,7.8,.86,3.45,1480\n",
    "...`\n",
    "\n",
    "First is the class of the wine and the follows the data, which are (taken from wines.names):<br>\n",
    "1) Alcohol\n",
    "2) Malic acid\n",
    "3) Ash\n",
    "4) Alcalinity of ash\n",
    "5) Magnesium\n",
    "6) Total phenols\n",
    "7) Flavanoids\n",
    "8) Nonflavanoid phenols\n",
    "9) Proanthocyanins\n",
    "10) Color intensity\n",
    "11) Hue\n",
    "12) OD280/OD315 of diluted wines\n",
    "13) Proline \n",
    "    \n",
    "    \n",
    "The data is clearly a simple CSV file, thus we start by reading the data.\n",
    "\n",
    "---\n",
    "\n",
    "* Author: Troels C. Petersen (NBI) & Brian Vinter (formerly NBI, now AU)\n",
    "* Email:  petersen@nbi.dk\n",
    "* Date:   25th of April 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy\n",
    "\n",
    "with open('data_Wine.csv') as input_file:\n",
    "    raw_data = numpy.array([row for row in csv.reader(input_file)]).astype(numpy.float)\n",
    "\n",
    "labels = raw_data[:, 0 ]\n",
    "data   = raw_data[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the data are not in the simple [0:1] range - so we normalize each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, num_c = data.shape\n",
    "for i in range(num_c):\n",
    "    data[:, i] = data[:, i] / numpy.max(data[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that there are 13 columns in data, but at this point we may as well make our distance meassure indepedent of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_distances(point, db):\n",
    "    result = []\n",
    "    for entry in db:\n",
    "        distance = 0.0\n",
    "        for dim in zip(point, entry):\n",
    "                distance += (dim[0] - dim[1])**2\n",
    "        result.append(numpy.sqrt(distance))\n",
    "    return numpy.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering:\n",
    "\n",
    "Your challenge is to see, if you can cluster the wine data using the various algorithms. Check (using the labels) how well you/the algorithms do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sidetrack: k-Nearest-Neighbor (i.e. classification):\n",
    "\n",
    "This part is not clustering, but classification based on the k nearest neighbors. We can reuse the simple election mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def classify(point, k=5):\n",
    "    distances = all_distances(point, data)\n",
    "    votes = []\n",
    "    for _ in range(k):\n",
    "        winner = numpy.argmin(distances)\n",
    "        votes.append(labels[winner])\n",
    "        distances[winner] = 1000\n",
    "    return collections.Counter(votes).most_common(1)[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the result against the database itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 176 of 178\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "for point in raw_data:\n",
    "    if point[0] == classify(point[1:], 6):\n",
    "        score += 1\n",
    "print('Matched', score, 'of', len(raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is quite satisfactory. However, since we are matching against the database itself, the tested point is itself in the test set, which is an unfair advantage compared to a real world scenario. Eliminating this bias is left as an exercise, it is quite simple though.\n",
    "\n",
    "You should play around with values of k as well, to tell the best number of neighbors to match against."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
